# Responsible AI: Bias, Safety & Toxicity Pipeline

This project builds responsible AI pipelines for LLM safety evaluation:

- Toxicity detection using pre-trained classifiers
- Bias benchmarks with demographic-sensitive prompts
- Content filtering logic

## Pipeline Components

1. Toxicity evaluation
2. Bias evaluation
3. Content filter engine

## Dependencies

- detoxify
- pandas
- numpy
- tqdm
- transformers
- sentence-transformers

